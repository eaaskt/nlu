{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated CapsnetsS2I train + test\n",
    "\n",
    "First, import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1109 19:05:45.318576 4620180928 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import model_s2i\n",
    "import data_loader\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load word vectors and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "WORD_VEC_SCENARIO = \"FastText-300-verbsDatasets-synAntVSP-dia\"\n",
    "SCENARIO_NAME = 'vec-100'\n",
    "\n",
    "word2vec_path = '../../romanian_word_vecs/cleaned-vectors-diacritice-100.vec'\n",
    "\n",
    "# No diacritics data\n",
    "training_data_paths = [\n",
    "#         '../data-capsnets/scenario0/train.txt',\n",
    "#         '../data-capsnets/scenario1/train.txt',\n",
    "#         '../data-capsnets/scenario2/train.txt',\n",
    "#         '../data-capsnets/scenario3.1/train.txt',\n",
    "#         '../data-capsnets/scenario3.2/train.txt',\n",
    "#         '../data-capsnets/scenario3.3/train.txt',\n",
    "        '../data-capsnets/diacritics/scenario0/train.txt',\n",
    "        '../data-capsnets/diacritics/scenario1/train.txt',\n",
    "        '../data-capsnets/diacritics/scenario2/train.txt',\n",
    "        '../data-capsnets/diacritics/scenario31/train.txt',\n",
    "        '../data-capsnets/diacritics/scenario32/train.txt',\n",
    "        '../data-capsnets/diacritics/scenario33/train.txt',\n",
    "        \n",
    "    ]\n",
    "test_data_paths = [\n",
    "#     '../data-capsnets/scenario0/test.txt',\n",
    "#     '../data-capsnets/scenario1/test.txt',\n",
    "#     '../data-capsnets/scenario2/test.txt',\n",
    "#     '../data-capsnets/scenario3.1/test.txt',\n",
    "#     '../data-capsnets/scenario3.2/test.txt',\n",
    "#     '../data-capsnets/scenario3.3/test.txt',\n",
    "    '../data-capsnets/diacritics/scenario0/test.txt',\n",
    "    '../data-capsnets/diacritics/scenario1/test.txt',\n",
    "    '../data-capsnets/diacritics/scenario2/test.txt',\n",
    "    '../data-capsnets/diacritics/scenario31/test.txt',\n",
    "    '../data-capsnets/diacritics/scenario32/test.txt',\n",
    "    '../data-capsnets/diacritics/scenario33/test.txt',\n",
    "]\n",
    "\n",
    "scenario_nums = [\n",
    "#     '0_' + WORD_VEC_SCENARIO,\n",
    "#     '1_' + WORD_VEC_SCENARIO,\n",
    "#     '2_' + WORD_VEC_SCENARIO,\n",
    "#     '31_' + WORD_VEC_SCENARIO,\n",
    "#     '32_' + WORD_VEC_SCENARIO,\n",
    "#     '33_' + WORD_VEC_SCENARIO,\n",
    "#     '0_dia_' + WORD_VEC_SCENARIO,\n",
    "#     '1_dia_' + WORD_VEC_SCENARIO,\n",
    "#     '2_dia_' + WORD_VEC_SCENARIO,\n",
    "#     '31_dia_' + WORD_VEC_SCENARIO,\n",
    "#     '32_dia_' + WORD_VEC_SCENARIO,\n",
    "#     '33_dia_' + WORD_VEC_SCENARIO,\n",
    "    '0-' + SCENARIO_NAME,\n",
    "    '1-' + SCENARIO_NAME,\n",
    "    '2-' + SCENARIO_NAME,\n",
    "    '31-' + SCENARIO_NAME,\n",
    "    '32-' + SCENARIO_NAME,\n",
    "    '33-' + SCENARIO_NAME,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------load word2vec begin-------------------\n",
      "loading time took 000.07\n",
      "------------------load word2vec end---------------------\n"
     ]
    }
   ],
   "source": [
    "print('------------------load word2vec begin-------------------')\n",
    "w2v = data_loader.load_w2v(word2vec_path)\n",
    "print('------------------load word2vec end---------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flag setting functions + utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def set_flags(data, scenario):\n",
    "    FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "    tf.app.flags.DEFINE_boolean('save_model', False, 'save model to disk')\n",
    "    tf.app.flags.DEFINE_string('summaries_dir', './logs', 'tensorboard summaries')\n",
    "    tf.app.flags.DEFINE_string('ckpt_dir', './saved_models/', 'check point dir')\n",
    "    tf.app.flags.DEFINE_string('scenario_num', scenario, 'Scenario number')\n",
    "    tf.app.flags.DEFINE_string('errors_dir', './errors/', 'Errors dir')\n",
    "    tf.app.flags.DEFINE_string('results_dir', './results/', 'Results dir')\n",
    "    tf.app.flags.DEFINE_string('hyperparams_dir', './hyperparams/', 'Hyperparams dir')\n",
    "    \n",
    "    vocab_size, word_emb_size = data['embedding'].shape\n",
    "    _, max_sentence_length = data['x_tr'].shape\n",
    "    intents_number = len(data['intents_dict'])\n",
    "    slots_number = len(data['slots_dict'])\n",
    "    hidden_size = 16\n",
    "\n",
    "    tf.app.flags.DEFINE_float('keep_prob', 1, 'embedding dropout keep rate for training')\n",
    "    tf.app.flags.DEFINE_integer('hidden_size', hidden_size, 'embedding vector size')\n",
    "    tf.app.flags.DEFINE_integer('batch_size', 32, 'batch size')\n",
    "    tf.app.flags.DEFINE_integer('num_epochs', 20, 'num of epochs')\n",
    "    tf.app.flags.DEFINE_integer('vocab_size', vocab_size, 'vocab size of word vectors')\n",
    "    tf.app.flags.DEFINE_integer('max_sentence_length', max_sentence_length, 'max number of words in one sentence')\n",
    "    tf.app.flags.DEFINE_integer('intents_nr', intents_number, 'intents_number')  #\n",
    "    tf.app.flags.DEFINE_integer('slots_nr', slots_number, 'slots_number')  #\n",
    "    tf.app.flags.DEFINE_integer('word_emb_size', word_emb_size, 'embedding size of word vectors')\n",
    "    tf.app.flags.DEFINE_boolean('use_embedding', True, 'whether to use embedding or not.')\n",
    "    tf.app.flags.DEFINE_float('learning_rate', 0.01, 'learning rate')\n",
    "    tf.app.flags.DEFINE_integer('slot_routing_num', 2, 'slot routing num')\n",
    "    tf.app.flags.DEFINE_integer('intent_routing_num', 3, 'intent routing num')\n",
    "    tf.app.flags.DEFINE_integer('intent_output_dim', 8, 'intent output dimension')\n",
    "    tf.app.flags.DEFINE_integer('slot_output_dim', 2 * hidden_size, 'slot output dimension')\n",
    "    tf.app.flags.DEFINE_integer('d_a', 10, 'self attention weight hidden units number')\n",
    "    tf.app.flags.DEFINE_integer('r', 3, 'number of self attention heads')\n",
    "    tf.app.flags.DEFINE_float('alpha', 0.0001, 'coefficient for self attention loss')\n",
    "    tf.app.flags.DEFINE_integer('n_splits', 3, 'Number of cross-validation splits')\n",
    "    tf.app.flags.DEFINE_float('rerouting_coef', 0.5, 'coefficient for rerouting')\n",
    "    tf.app.flags.DEFINE_boolean('use_rerouting', True, 'whether to use rerouting or not')\n",
    "    tf.app.flags.DEFINE_boolean('use_attention', True,\n",
    "                                'whether to use attention or not. If attention is used,'\n",
    "                                'slot_output_dim will be overridden to hidden_size * 2')\n",
    "    \n",
    "    tf.app.flags.DEFINE_string('f', '', 'kernel') # Without this there's an error: unknown command line flag 'f'\n",
    "    \n",
    "    return FLAGS\n",
    "\n",
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()\n",
    "    keys_list = [keys for keys in flags_dict]\n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "        \n",
    "def write_csv(run_results):\n",
    "    with open('results/results_{}.csv'.format(SCENARIO_NAME), 'w') as f:\n",
    "        header_line = ['Scenario', 'Intent F1', 'Slot F1']\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header_line)\n",
    "        for k, v in run_results.items():\n",
    "            scenario_num = [k]\n",
    "            intent_score = [v['intent_f1']]\n",
    "            slot_score = [v['slot_f1']]\n",
    "            l = scenario_num + intent_score + slot_score\n",
    "            writer.writerow(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# In case it's needed\n",
    "del_all_flags(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------read datasets begin-------------------\n",
      "max length is 15\n",
      "max length is 15\n",
      "------------------read datasets end---------------------\n"
     ]
    },
    {
     "ename": "DuplicateFlagError",
     "evalue": "The flag 'save_model' is defined twice. First from /Users/andastoica/Master/Project/code/nlu/capsnet-arch/venv/lib/python3.7/site-packages/ipykernel_launcher.py, Second from /Users/andastoica/Master/Project/code/nlu/capsnet-arch/venv/lib/python3.7/site-packages/ipykernel_launcher.py.  Description from first occurrence: save model to disk",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-027b05417be7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mFLAGS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscenario_nums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f14115827654>\u001b[0m in \u001b[0;36mset_flags\u001b[0;34m(data, scenario)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mFLAGS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'save_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'save model to disk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'summaries_dir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tensorboard summaries'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ckpt_dir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./saved_models/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'check point dir'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Master/Project/code/nlu/capsnet-arch/venv/lib/python3.7/site-packages/tensorflow_core/python/platform/flags.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;34m'Use of the keyword argument names (flag_name, default_value, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m           'docstring) is deprecated, please use (name, default, help) instead.')\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Master/Project/code/nlu/capsnet-arch/venv/lib/python3.7/site-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_boolean\u001b[0;34m(name, default, help, flag_values, module_name, **args)\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m    267\u001b[0m   DEFINE_flag(_flag.BooleanFlag(name, default, help, **args),\n\u001b[0;32m--> 268\u001b[0;31m               flag_values, module_name)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Master/Project/code/nlu/capsnet-arch/venv/lib/python3.7/site-packages/absl/flags/_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[0;34m(flag, flag_values, module_name)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0mfv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m   \u001b[0mfv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m   \u001b[0;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Master/Project/code/nlu/capsnet-arch/venv/lib/python3.7/site-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, flag)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateFlagError\u001b[0m: The flag 'save_model' is defined twice. First from /Users/andastoica/Master/Project/code/nlu/capsnet-arch/venv/lib/python3.7/site-packages/ipykernel_launcher.py, Second from /Users/andastoica/Master/Project/code/nlu/capsnet-arch/venv/lib/python3.7/site-packages/ipykernel_launcher.py.  Description from first occurrence: save model to disk"
     ]
    }
   ],
   "source": [
    "import train\n",
    "import test\n",
    "\n",
    "results = dict()\n",
    "for i in range(len(training_data_paths)):\n",
    "    \n",
    "    # Load data\n",
    "    isLowercase = True # When using the new 100-dim word vec model, the data should all be in lowercase\n",
    "    data = data_loader.read_datasets(w2v, training_data_paths[i], test_data_paths[i], test=True, lowercase=isLowercase)\n",
    "    \n",
    "    FLAGS = set_flags(data, scenario=scenario_nums[i])\n",
    "    \n",
    "    # Train model\n",
    "    print('TRAINING ' + scenario_nums[i])\n",
    "    train.train(model_s2i.CapsNetS2I, data, FLAGS, batches_rand=False)\n",
    "    \n",
    "    # Test model\n",
    "    print('TESTING ' + scenario_nums[i])\n",
    "    intent_f, slot_f = test.test(model_s2i.CapsNetS2I, data, FLAGS)\n",
    "    results[scenario_nums[i]] = dict()\n",
    "    results[scenario_nums[i]]['intent_f1'] = intent_f\n",
    "    results[scenario_nums[i]]['slot_f1'] = slot_f\n",
    "        \n",
    "    # Reset flags\n",
    "    del_all_flags(FLAGS)\n",
    "\n",
    "write_csv(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}